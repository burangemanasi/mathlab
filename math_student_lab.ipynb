{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Math Lab — FAANG-Level Mixed Problems\n",
        "\n",
        "This lab is a *problem set + mini-verification* notebook.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def check(name: str, cond: bool):\n",
        "    if not cond:\n",
        "        raise AssertionError(f'Failed: {name}')\n",
        "    print(f'OK: {name}')\n",
        "\n",
        "rng = np.random.default_rng(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 1 — Projection Matrix Properties\n",
        "\n",
        "Let P be a projection matrix onto a subspace.\n",
        "1) Show that P^2 = P (idempotent).\n",
        "2) For orthogonal projection, show P = P^T.\n",
        "\n",
        "### TODO (code): Construct projection onto span(u) and verify properties\n",
        "# HINT:\n",
        "P = u u^T / (u^T u)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: idempotent\n",
            "OK: symmetric\n"
          ]
        }
      ],
      "source": [
        "u = rng.standard_normal(5)          # generate a random 5-dimensional vector\n",
        "\n",
        "P = np.outer(u, u) / (u @ u)        # constructing projection matrix onto the direction of vector u\n",
        "check('idempotent', np.allclose(P @ P, P, atol=1e-8))   # verify idempotence property\n",
        "check('symmetric', np.allclose(P, P.T, atol=1e-8))      # verify symmetry property"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 2 — PSD Matrix Check\n",
        "\n",
        "Show that for any matrix X, the matrix A = X^T X is positive semidefinite (PSD).\n",
        "\n",
        "### TODO (code): sample random X, build A, verify v^T A v >= 0 for random v\n",
        "# HINT:\n",
        "v^T X^T X v = ||Xv||^2 >= 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PSD check passed\n"
          ]
        }
      ],
      "source": [
        "X = rng.standard_normal((10, 4))            # generate data matrix with 10 samples and 4 features\n",
        "A = X.T @ X                                 # form Gram matrix which is symmetric and positive semidefinite\n",
        "for _ in range(100):\n",
        "    v = rng.standard_normal(4)              # Generate random test vector\n",
        "    val = float(v.T @ A @ v)                # Compute quadratic form to test positive semidefiniteness\n",
        "    if val < -1e-8:                         # small numerical error is allowed but reject negative values\n",
        "        raise AssertionError('Not PSD?')    # AssertionError if matrix violates PSD property\n",
        "print('PSD check passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 3 — Least Squares Derivation\n",
        "\n",
        "Derive the normal equations for minimizing ||Xw - y||^2.\n",
        "\n",
        "### TODO (code): compare w_hat from solve vs np.linalg.lstsq\n",
        "# HINT:\n",
        "w = (X^T X)^{-1} X^T y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: close\n"
          ]
        }
      ],
      "source": [
        "n,d = 200, 5                                # number of samples (n) and number of features (d)\n",
        "X = rng.standard_normal((n,d))              # feature matrix with random values\n",
        "w_true = rng.standard_normal(d)             # generate true weight vector\n",
        "y = X@w_true + 0.1*rng.standard_normal(n)   # adding noise to w_true and generate target values as linear combination of features\n",
        "\n",
        "w_hat = np.linalg.solve(X.T @ X, X.T @ y)   # compute closed-form least squares solution using normal equation\n",
        "\n",
        "w_lstsq, *_ = np.linalg.lstsq(X, y, rcond=None)         # compute least squares solution using numerically stable built-in solver\n",
        "check('close', np.allclose(w_hat, w_lstsq, atol=1e-6))  # verify both methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 4 — Bayes + Base Rate (Derivation)\n",
        "\n",
        "Re-derive P(D|+) for the disease test scenario and explain the base-rate fallacy in 2-3 sentences.\n",
        "\n",
        "### TODO (code): simulate and compare to analytic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The base rate fallacy is ignoring how common something is (the prior probability) when interpreting new evidence. People overestimate the possibility of a disease after a positive test by focusing on test accuracy and forgetting that the disease itself may be rare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.16666666666666669\n",
            "analytic 0.16666666666666669 sim 0.16930459673345682\n",
            "OK: close\n"
          ]
        }
      ],
      "source": [
        "P_D = 0.01                  # probability of having the disease\n",
        "P_pos_given_D = 0.99        # probability of positive test given disease\n",
        "P_pos_given_notD = 0.05     # Probability of positive test given no disease\n",
        "P_D_given_pos = (P_pos_given_D*P_D) / (P_pos_given_D*P_D + P_pos_given_notD*(1-P_D))  # Bayes’ theorem to compute probability of disease\n",
        "print(P_D_given_pos)\n",
        "\n",
        "N = 200000                              # number of samples\n",
        "disease = rng.random(N) < P_D           # simulate disease occurrence using prior probability\n",
        "test_pos = np.empty(N, dtype=bool)      # allocate array to store test outcomes\n",
        "test_pos[disease] = rng.random(disease.sum()) < P_pos_given_D           # positive tests for diseased individuals\n",
        "test_pos[~disease] = rng.random((~disease).sum()) < P_pos_given_notD    # false positives for healthy individuals\n",
        "est = disease[test_pos].mean()          # Estimate P(D|+)\n",
        "print('analytic', P_D_given_pos, 'sim', est)\n",
        "check('close', abs(est - P_D_given_pos) < 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 5 — PCA Link\n",
        "\n",
        "Explain why PCA components are eigenvectors of the covariance matrix.\n",
        "\n",
        "### TODO (code): compute covariance eigenvectors and compare with SVD directions\n",
        "# HINT:\n",
        "- Center X\n",
        "- Cov = X^T X/(n-1)\n",
        "- eigenvectors of Cov align with V from SVD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA components are eigenvectors because eigenvectors of the covariance matrix are exactly the directions of maximum variance in the data, they maximize variance under orthogonality constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abs alignment matrix (should be near diagonal) [[1.00000000e+00 3.01139914e-14 2.14267735e-15 3.90646844e-15\n",
            "  8.11237365e-16]\n",
            " [3.09196500e-14 1.00000000e+00 4.24782438e-15 8.47505382e-15\n",
            "  6.40337552e-15]\n",
            " [2.04648869e-15 4.20577497e-15 1.00000000e+00 4.78971369e-14\n",
            "  1.08537281e-14]\n",
            " [4.04548183e-15 8.20584485e-15 4.89486685e-14 1.00000000e+00\n",
            "  6.03181136e-15]\n",
            " [7.35522754e-16 6.67521594e-15 1.13381526e-14 6.34908792e-15\n",
            "  1.00000000e+00]]\n",
            "OK: alignment\n"
          ]
        }
      ],
      "source": [
        "X = rng.standard_normal((500, 20))                  # generate dataset with 500 samples and 20 features\n",
        "Xc = X - X.mean(axis=0, keepdims=True)              # center each feature by subtracting its mean\n",
        "Cov = (Xc.T @ Xc) / (Xc.shape[0] - 1)               # compute sample covariance matrix\n",
        "eigvals, eigvecs = np.linalg.eigh(Cov)              # compute eigenvalues and eigenvectors of covariance matrix\n",
        "idx = np.argsort(eigvals)[::-1]                     # sort eigenvalues in descending order\n",
        "eigvecs = eigvecs[:, idx]                           # reorder eigenvectors to match sorted eigenvalues\n",
        "\n",
        "U, S, Vt = np.linalg.svd(Xc, full_matrices=False)   # SVD on centered data matrix\n",
        "V = Vt.T                                            # extract right singular vectors\n",
        "\n",
        "# Compare subspaces spanned by top-k vectors via absolute correlation\n",
        "k = 5\n",
        "C = np.abs(eigvecs[:, :k].T @ V[:, :k])             # Measure alignment between PCA directions from both methods\n",
        "print('abs alignment matrix (should be near diagonal)', C)\n",
        "check('alignment', np.all(np.max(C, axis=1) > 0.9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Submission Checklist\n",
        "- Derivations written\n",
        "- TODO code complete\n",
        "- Checks pass\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
